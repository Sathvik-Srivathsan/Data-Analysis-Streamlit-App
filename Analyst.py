# app.py
import streamlit as st
import pandas as pd
import pypdf
import docx
import os
import requests
import io
import matplotlib.pyplot as plt
import plotly.express as px
import re

# --- IMPORTANT: API Key Configuration ---
# It's highly recommended to use Streamlit Secrets to store your API key.
# 1. Create a folder named .streamlit in your project directory.
# 2. Inside it, create a file named secrets.toml.
# 3. Add your API key to secrets.toml like this:
#    TOGETHER_API_KEY = "your_actual_api_key_here"
# The code below will automatically read this key.
try:
    TOGETHER_API_KEY = st.secrets["TOGETHER_API_KEY"]
except (FileNotFoundError, KeyError):
    st.error("API Key not found. Please create a .streamlit/secrets.toml file and add your TOGETHER_API_KEY.")
    TOGETHER_API_KEY = None


# --- Helper Functions for File Processing ---

def process_text(file_contents):
    """Processes text from a .txt file."""
    return file_contents.decode("utf-8")

def process_pdf(file):
    """Processes text from a .pdf file."""
    pdf_reader = pypdf.PdfReader(file)
    text = ""
    for page in pdf_reader.pages:
        text += page.extract_text() or "" # Add check for None
    return text

def process_docx(file):
    """Processes text from a .docx file."""
    doc = docx.Document(file)
    text = ""
    for para in doc.paragraphs:
        text += para.text + "\n"
    return text

def process_csv(file):
    """Processes data from a .csv file and returns it as a DataFrame."""
    try:
        file.seek(0)
        df = pd.read_csv(file)
        return df
    except Exception as e:
        st.error(f"Error processing CSV: {e}")
        return None

def process_xlsx(file):
    """Processes data from an .xlsx file and returns it as a DataFrame."""
    try:
        file.seek(0)
        df = pd.read_excel(file)
        return df
    except Exception as e:
        st.error(f"Error processing Excel: {e}")
        return None

# --- Visualization Function ---

def execute_viz_code(code, df):
    """
    Executes the visualization code generated by the LLM.
    The AI is instructed to generate a complete, runnable script
    that includes the Streamlit display call (e.g., st.plotly_chart).
    """
    if code:
        try:
            local_vars = {"st": st, "pd": pd, "px": px, "df": df}
            exec(code, {}, local_vars)
        except Exception as e:
            st.error(f"Error executing visualization code: {e}")
            st.code(code)


# --- Function to Query the Together.ai API ---

def query_together_ai(api_key, context, question, chat_history):
    """
    Sends a structured query to the Together.ai API and returns the response.
    """
    if not api_key:
        st.error("API Key is not set. Please add it to your Streamlit secrets.")
        return None

    url = "https://api.together.xyz/v1/chat/completions"
    # Note: Switched to a different model. You can try other models if you still face rate limits.
    # Original model: "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8"
    model_name = "mistralai/Mixtral-8x7B-Instruct-v0.1"

    # This is the system prompt that instructs the AI on its role and how to behave.
    system_prompt = """
    You are an expert data analyst working inside a Streamlit app. Your goal is to help a user analyze their data.

    **Instructions:**
    1.  Analyze the provided data context and the user's question from the conversation history.
    2.  If the user asks for a visualization, you MUST generate Python code to create and display a plot within Streamlit.
    3.  The data is available in a pandas DataFrame named `df`.
    4.  Use the `plotly.express` library (imported as `px`) for all visualizations. Do not use matplotlib.
    5.  After creating a figure (e.g., `fig = px.histogram(df, x='some_column')`), you MUST display it using `st.plotly_chart(fig)`.
    6.  Your response for a visualization request MUST ONLY be the Python code block, enclosed in ```python ... ```. Do not add any explanation or other text.
    7.  If the user asks a general question that does not require a plot, provide a clear and concise text-based answer without any code.
    """

    # Build the message list for the API call
    messages = [{"role": "system", "content": system_prompt}]

    # Add data context for the model to reference
    messages.append({"role": "user", "content": f"Here is the data context you need to analyze:\n\n--- DATA CONTEXT ---\n{context}\n--- END OF DATA CONTEXT ---"})
    messages.append({"role": "assistant", "content": "Understood. I have the data context. I am ready to answer questions or create visualizations based on it."})

    # Add previous messages from the chat history
    for msg in chat_history:
        messages.append(msg)

    # Add the latest user question
    messages.append({"role": "user", "content": question})


    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    payload = {
        "model": model_name,
        "max_tokens": 2048,
        "temperature": 0.5,
        "top_p": 0.7,
        "top_k": 50,
        "repetition_penalty": 1,
        "messages": messages
    }

    try:
        response = requests.post(url, headers=headers, json=payload, timeout=60)
        response.raise_for_status()
        data = response.json()
        return data['choices'][0]['message']['content']
    except requests.exceptions.RequestException as e:
        st.error(f"Error calling Together.ai API: {e}")
        if e.response:
            st.error(f"Response content: {e.response.content.decode()}")
        return None
    except (KeyError, IndexError) as e:
        st.error(f"Unexpected response format from API: {e}")
        st.write(response.json())
        return None


# --- Streamlit App UI ---

st.set_page_config(page_title="Data Analyst Agent", layout="wide")

st.title("ðŸ¤– Intelligent Data Analyst Agent")
st.markdown("Upload a document (.txt, .pdf, .docx, .csv, .xlsx) and ask questions about it. For API key setup, see comments in the code.")

# --- Session State Initialization ---
if 'file_context_str' not in st.session_state:
    st.session_state.file_context_str = None
if 'dataframe' not in st.session_state:
    st.session_state.dataframe = None
if 'file_name' not in st.session_state:
    st.session_state.file_name = None
if 'messages' not in st.session_state:
    st.session_state.messages = []


# --- Sidebar for File Upload ---
with st.sidebar:
    st.header("Upload Data")
    uploaded_file = st.file_uploader(
        "Choose a file",
        type=["txt", "pdf", "docx", "csv", "xlsx"]
    )

    if uploaded_file is not None:
        # Clear state on new file upload
        if st.session_state.get('file_name') != uploaded_file.name:
            st.session_state.messages = []
            st.session_state.file_name = uploaded_file.name
            st.session_state.dataframe = None
            st.session_state.file_context_str = None

            with st.spinner(f"Processing {uploaded_file.name}..."):
                file_extension = os.path.splitext(uploaded_file.name)[1].lower()
                file_wrapper = io.BytesIO(uploaded_file.getvalue())

                context_str = ""
                df = None

                if file_extension == ".txt":
                    context_str = process_text(file_wrapper.read())
                elif file_extension == ".pdf":
                    context_str = process_pdf(file_wrapper)
                elif file_extension == ".docx":
                    context_str = process_docx(file_wrapper)
                elif file_extension in [".csv", ".xlsx"]:
                    if file_extension == ".csv":
                        df = process_csv(file_wrapper)
                    else:
                        df = process_xlsx(file_wrapper)

                    if df is not None:
                        st.session_state.dataframe = df
                        # For dataframes, context can be a summary instead of the full thing
                        context_str = f"Dataframe columns: {df.columns.tolist()}\nFirst 5 rows:\n{df.head().to_string()}"
                        st.dataframe(df.head()) # Show preview in sidebar
                    else:
                        context_str = "Error processing the file."
                else:
                    context_str = "Unsupported file type."

                st.session_state.file_context_str = context_str
                st.success("File processed successfully!")
                st.info("You can now ask questions about the document.")


# --- Main Chat Interface ---

if st.session_state.get('file_name'):
    st.subheader(f"Chat about: `{st.session_state.file_name}`")

    # Display chat messages
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            # Check for python code blocks in the message
            code_match = re.search(r"```python\n(.*?)```", message["content"], re.DOTALL)
            if code_match and message["role"] == "assistant":
                code = code_match.group(1).strip()
                st.markdown("Here is the visualization you requested:")
                execute_viz_code(code, st.session_state.dataframe)
            else:
                st.markdown(message["content"])

    # Chat input
    if prompt := st.chat_input("Ask a question about your document..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("Analyzing..."):
                if st.session_state.file_context_str:
                    # Pass the last 10 messages for history context
                    chat_history = st.session_state.messages[-11:-1]

                    response = query_together_ai(
                        TOGETHER_API_KEY,
                        st.session_state.file_context_str,
                        prompt,
                        chat_history
                    )
                    if response:
                        st.session_state.messages.append({"role": "assistant", "content": response})

                        # Check for and execute visualization code from the new response
                        code_match = re.search(r"```python\n(.*?)```", response, re.DOTALL)
                        if code_match:
                            code = code_match.group(1).strip()
                            st.markdown("Here is the visualization you requested:")
                            execute_viz_code(code, st.session_state.dataframe)
                        else:
                            st.markdown(response)
                    else:
                        st.error("Failed to get a response from the agent.")
                else:
                    st.warning("Please upload a file first.")
else:
    st.info("Please upload a file using the sidebar to begin.")

